{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Euy3nr3unKcc3ysycQPtjsvG8q78bBUn",
      "authorship_tag": "ABX9TyN+fuQY+yUNEQ1pcXEWANMK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsabellaGarzon/RetoSofka/blob/main/EntregableFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMIls3U630iP",
        "outputId": "146d2be4-aa37-4414-bf28-e0dc823e6be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Quadratic Discriminant Analysis\n",
            "Accuracy mean: 0.38888888888888884\n",
            "Precision mean: 0.0\n",
            "Recall mean: 0.0\n",
            "F1 mean: 0.0\n",
            "\n",
            "Model: Parzen Window (Kernel Density)\n",
            "Accuracy mean: 0.611111111111111\n",
            "Precision mean: 0.611111111111111\n",
            "Recall mean: 1.0\n",
            "F1 mean: 0.7555555555555555\n",
            "\n",
            "Model: Gradient Boosting Tree\n",
            "Accuracy mean: 0.7222222222222222\n",
            "Precision mean: 0.8333333333333334\n",
            "Recall mean: 0.8333333333333334\n",
            "F1 mean: 0.7777777777777777\n",
            "\n",
            "Model: Artificial Neural Network\n",
            "Accuracy mean: 0.49999999999999994\n",
            "Precision mean: 0.38888888888888884\n",
            "Recall mean: 0.6666666666666666\n",
            "F1 mean: 0.48888888888888893\n",
            "\n",
            "Model: Support Vector Machines\n",
            "Accuracy mean: 0.611111111111111\n",
            "Precision mean: 0.611111111111111\n",
            "Recall mean: 1.0\n",
            "F1 mean: 0.7555555555555555\n",
            "\n",
            "Overall Metrics:\n",
            "Accuracy: [0.38888888888888884, 0.611111111111111, 0.7222222222222222, 0.49999999999999994, 0.611111111111111]\n",
            "Precision: [0.0, 0.611111111111111, 0.8333333333333334, 0.38888888888888884, 0.611111111111111]\n",
            "Recall: [0.0, 1.0, 0.8333333333333334, 0.6666666666666666, 1.0]\n",
            "F1: [0.0, 0.7555555555555555, 0.7777777777777777, 0.48888888888888893, 0.7555555555555555]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KernelDensity\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/lib/ADMISSIONS.csv')\n",
        "df_sepsis = df[df['diagnosis'] == 'SEPSIS']\n",
        "\n",
        "y = df_sepsis[\"deathtime\"]\n",
        "X = df_sepsis.drop(\"deathtime\", axis=1)\n",
        "\n",
        "k = 5\n",
        "cv = StratifiedKFold(n_splits=k)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "X = X.fillna(0)\n",
        "X = X.drop(columns=['admittime', 'dischtime','edregtime','subject_id','row_id'])\n",
        "X = X.select_dtypes(exclude=['object'])\n",
        "y = y.notnull().astype('int')\n",
        "\n",
        "y = y.apply(lambda x: 1 if x != 0 else 0)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "modelos = [\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    KernelDensity(),\n",
        "    GradientBoostingClassifier(),\n",
        "    MLPClassifier(),\n",
        "    SVC()\n",
        "]\n",
        "\n",
        "model_names = [\n",
        "    \"Quadratic Discriminant Analysis\",\n",
        "    \"Parzen Window (Kernel Density)\",\n",
        "    \"Gradient Boosting Tree\",\n",
        "    \"Artificial Neural Network\",\n",
        "    \"Support Vector Machines\"\n",
        "]\n",
        "\n",
        "for modelo, model_name in zip(modelos, model_names):\n",
        "    accuracy_model = []\n",
        "    precision_model = []\n",
        "    recall_model = []\n",
        "    f1_model = []\n",
        "    \n",
        "    for train_index, test_index in cv.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        if isinstance(modelo, KernelDensity):\n",
        "            modelo.fit(X_train)\n",
        "            log_density = modelo.score_samples(X_test)\n",
        "            threshold = 0.0\n",
        "            y_pred = (log_density < threshold).astype(int)\n",
        "        else:\n",
        "            modelo.fit(X_train, y_train)\n",
        "            y_pred = modelo.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        accuracy_model.append(accuracy)\n",
        "        precision_model.append(precision)\n",
        "        recall_model.append(recall)\n",
        "        f1_model.append(f1)\n",
        "\n",
        "    accuracy_mean = np.mean(accuracy_model)\n",
        "    precision_mean = np.mean(precision_model)\n",
        "    recall_mean = np.mean(recall_model)\n",
        "    f1_mean = np.mean(f1_model)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Accuracy mean:\", accuracy_mean)\n",
        "    print(\"Precision mean:\", precision_mean)\n",
        "    print(\"Recall mean:\", recall_mean)\n",
        "    print(\"F1 mean:\", f1_mean)\n",
        "    print()\n",
        "\n",
        "    accuracy_scores.append(accuracy_mean)\n",
        "    precision_scores.append(precision_mean)\n",
        "    recall_scores.append(recall_mean)\n",
        "    f1_scores.append(f1_mean)\n",
        "\n",
        "print(\"Overall Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_scores)\n",
        "print(\"Precision:\", precision_scores)\n",
        "print(\"Recall:\", recall_scores)\n",
        "print(\"F1:\", f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realice selección de características por el método de \n",
        "búsqueda secuencial ascendente o descendente y \n",
        "evalué nuevamente en los 3 mejores modelos \n",
        "evaluados**"
      ],
      "metadata": {
        "id": "gxWn16m8kFuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/lib/ADMISSIONS.csv')\n",
        "\n",
        "df_sepsis = df[df['diagnosis'] == 'SEPSIS']\n",
        "\n",
        "y = df_sepsis[\"deathtime\"]\n",
        "X = df_sepsis.drop(\"deathtime\", axis=1)\n",
        "\n",
        "k = 5\n",
        "\n",
        "cv = StratifiedKFold(n_splits=k)\n",
        "\n",
        "X = X.fillna(0)\n",
        "X = X.drop(columns=['admittime', 'dischtime', 'edregtime', 'subject_id', 'row_id'])\n",
        "X = X.select_dtypes(exclude=['object'])\n",
        "y = y.notnull().astype('int')\n",
        "\n",
        "y = y.apply(lambda x: 1 if x != 0 else 0)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "modelos = [\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    GradientBoostingClassifier(),\n",
        "    SVC()\n",
        "]\n",
        "\n",
        "model_names = [\n",
        "    \"Quadratic Discriminant Analysis\",\n",
        "    \"Gradient Boosting Tree\",\n",
        "    \"Support Vector Machines\"\n",
        "]\n",
        "\n",
        "selected_features = []\n",
        "\n",
        "results_table = pd.DataFrame(columns=[\"Selected Features\", \"Metric\"])\n",
        "\n",
        "while len(selected_features) < X.shape[1]:\n",
        "    best_metric = -np.inf\n",
        "    best_feature = None\n",
        "    \n",
        "    for feature in X.columns:\n",
        "        if feature not in selected_features:\n",
        "            current_features = selected_features + [feature]\n",
        "            f1_scores = []\n",
        "\n",
        "            for train_index, test_index in cv.split(X[current_features], y):\n",
        "                X_train, X_test = X[current_features].iloc[train_index], X[current_features].iloc[test_index]\n",
        "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "                for modelo, model_name in zip(modelos, model_names):\n",
        "                    modelo.fit(X_train, y_train)\n",
        "                    y_pred = modelo.predict(X_test)\n",
        "                    f1_scores.append(f1_score(y_test, y_pred))\n",
        "            \n",
        "            metric_avg = np.mean(f1_scores)\n",
        "\n",
        "            if metric_avg > best_metric:\n",
        "                best_metric = metric_avg\n",
        "                best_feature = feature\n",
        "    \n",
        "    selected_features.append(best_feature)    \n",
        "    results_table = results_table.append({\"Selected Features\": best_feature, \"Metric\": best_metric}, ignore_index=True)\n",
        "    \n",
        "print(\"Selected Features:\", selected_features)\n",
        "\n",
        "print(\"\\nResults Table:\")\n",
        "print(results_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeCMHTEwV4gU",
        "outputId": "87a3aa57-02f0-43a7-96a8-f9799089a40b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:955: RuntimeWarning: invalid value encountered in add\n",
            "  return -0.5 * (norm2 + u) + np.log(self.priors_)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:955: RuntimeWarning: invalid value encountered in add\n",
            "  return -0.5 * (norm2 + u) + np.log(self.priors_)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "<ipython-input-26-9fe0199fbff2>:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\"Selected Features\": best_feature, \"Metric\": best_metric}, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "<ipython-input-26-9fe0199fbff2>:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\"Selected Features\": best_feature, \"Metric\": best_metric}, ignore_index=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features: ['hadm_id', 'hospital_expire_flag', 'has_chartevents_data']\n",
            "\n",
            "Results Table:\n",
            "      Selected Features    Metric\n",
            "0               hadm_id  0.814815\n",
            "1  hospital_expire_flag  0.511111\n",
            "2  has_chartevents_data  0.511111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply\n",
            "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log\n",
            "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
            "<ipython-input-26-9fe0199fbff2>:70: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  results_table = results_table.append({\"Selected Features\": best_feature, \"Metric\": best_metric}, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realice extracción de características por el método\n",
        "PCA y evalúe nuevamente en los 3 mejores modelos \n",
        "de predicción evaluados.**"
      ],
      "metadata": {
        "id": "S5CTl-j4kS-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/lib/ADMISSIONS.csv')\n",
        "\n",
        "df_sepsis = df[df['diagnosis'] == 'SEPSIS']\n",
        "\n",
        "y = df_sepsis[\"deathtime\"]\n",
        "X = df_sepsis.drop(\"deathtime\", axis=1)\n",
        "\n",
        "k = 5\n",
        "cv = StratifiedKFold(n_splits=k)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "reduction_percentages = []\n",
        "\n",
        "X = X.fillna(0)\n",
        "X = X.drop(columns=['admittime', 'dischtime','edregtime','subject_id','row_id'])\n",
        "X = X.select_dtypes(exclude=['object'])\n",
        "y = y.notnull().astype('int')\n",
        "\n",
        "y = y.apply(lambda x: 1 if x != 0 else 0)\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "modelos = [\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    KernelDensity(),\n",
        "    GradientBoostingClassifier(),\n",
        "    MLPClassifier(),\n",
        "    SVC()\n",
        "]\n",
        "\n",
        "model_names = [\n",
        "    \"Quadratic Discriminant Analysis\",\n",
        "    \"Parzen Window (Kernel Density)\",\n",
        "    \"Gradient Boosting Tree\",\n",
        "    \"Artificial Neural Network\",\n",
        "    \"Support Vector Machines\"\n",
        "]\n",
        "\n",
        "for modelo, model_name in zip(modelos, model_names):\n",
        "    accuracy_model = []\n",
        "    precision_model = []\n",
        "    recall_model = []\n",
        "    f1_model = []\n",
        "    reduction_model = []\n",
        "    \n",
        "    for train_index, test_index in cv.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        pca = PCA(n_components=0.95)\n",
        "        X_train_pca = pca.fit_transform(X_train)\n",
        "        X_test_pca = pca.transform(X_test)\n",
        "\n",
        "        if isinstance(modelo, KernelDensity):\n",
        "            modelo.fit(X_train_pca)            \n",
        "            log_density = modelo.score_samples(X_test_pca)            \n",
        "            threshold = 0.0\n",
        "            y_pred = (log_density < threshold).astype(int)\n",
        "        else:\n",
        "            modelo.fit(X_train_pca, y_train)            \n",
        "            y_pred = modelo.predict(X_test_pca)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        accuracy_model.append(accuracy)\n",
        "        precision_model.append(precision)\n",
        "        recall_model.append(recall)\n",
        "        f1_model.append(f1)\n",
        "        \n",
        "        original_features = X_train.shape[1]\n",
        "        reduced_features = X_train_pca.shape[1]\n",
        "        reduction = ((original_features - reduced_features) / original_features) * 100\n",
        "        reduction_model.append(reduction)\n",
        "\n",
        "    accuracy_mean = np.mean(accuracy_model)\n",
        "    precision_mean = np.mean(precision_model)\n",
        "    recall_mean = np.mean(recall_model)\n",
        "    f1_mean = np.mean(f1_model)\n",
        "    reduction_mean = np.mean(reduction_model)\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(\"Accuracy mean:\", accuracy_mean)\n",
        "    print(\"Precision mean:\", precision_mean)\n",
        "    print(\"Recall mean:\", recall_mean)\n",
        "    print(\"F1 mean:\", f1_mean)\n",
        "    print(\"Reduction Percentage:\", reduction_mean)\n",
        "    print()\n",
        "\n",
        "    accuracy_scores.append(accuracy_mean)\n",
        "    precision_scores.append(precision_mean)\n",
        "    recall_scores.append(recall_mean)\n",
        "    f1_scores.append(f1_mean)\n",
        "    reduction_percentages.append(reduction_mean)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    \"Model\": model_names,\n",
        "    \"Reduction Percentage\": reduction_percentages,\n",
        "    \"Accuracy\": accuracy_scores,\n",
        "    \"Precision\": precision_scores,\n",
        "    \"Recall\": recall_scores,\n",
        "    \"F1\": f1_scores\n",
        "})\n",
        "\n",
        "print(\"Overall Metrics:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVee1KOJkZ8k",
        "outputId": "6c948f08-7dcf-43c2-ac72-2dcb36741c7f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Quadratic Discriminant Analysis\n",
            "Accuracy mean: 0.7222222222222222\n",
            "Precision mean: 0.8333333333333334\n",
            "Recall mean: 0.8333333333333334\n",
            "F1 mean: 0.7777777777777777\n",
            "Reduction Percentage: 66.66666666666666\n",
            "\n",
            "Model: Parzen Window (Kernel Density)\n",
            "Accuracy mean: 0.611111111111111\n",
            "Precision mean: 0.611111111111111\n",
            "Recall mean: 1.0\n",
            "F1 mean: 0.7555555555555555\n",
            "Reduction Percentage: 66.66666666666666\n",
            "\n",
            "Model: Gradient Boosting Tree\n",
            "Accuracy mean: 0.7222222222222222\n",
            "Precision mean: 0.8333333333333334\n",
            "Recall mean: 0.8333333333333334\n",
            "F1 mean: 0.7777777777777777\n",
            "Reduction Percentage: 66.66666666666666\n",
            "\n",
            "Model: Artificial Neural Network\n",
            "Accuracy mean: 0.5\n",
            "Precision mean: 0.5\n",
            "Recall mean: 0.5\n",
            "F1 mean: 0.4444444444444444\n",
            "Reduction Percentage: 66.66666666666666\n",
            "\n",
            "Model: Support Vector Machines\n",
            "Accuracy mean: 0.8333333333333334\n",
            "Precision mean: 0.8333333333333334\n",
            "Recall mean: 1.0\n",
            "F1 mean: 0.8888888888888888\n",
            "Reduction Percentage: 66.66666666666666\n",
            "\n",
            "Overall Metrics:\n",
            "                             Model  Reduction Percentage  Accuracy  Precision  \\\n",
            "0  Quadratic Discriminant Analysis             66.666667  0.722222   0.833333   \n",
            "1   Parzen Window (Kernel Density)             66.666667  0.611111   0.611111   \n",
            "2           Gradient Boosting Tree             66.666667  0.722222   0.833333   \n",
            "3        Artificial Neural Network             66.666667  0.500000   0.500000   \n",
            "4          Support Vector Machines             66.666667  0.833333   0.833333   \n",
            "\n",
            "     Recall        F1  \n",
            "0  0.833333  0.777778  \n",
            "1  1.000000  0.755556  \n",
            "2  0.833333  0.777778  \n",
            "3  0.500000  0.444444  \n",
            "4  1.000000  0.888889  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=[\"row_id\", \"subject_id\"])\n",
        "correlation_matrix = df.corr(numeric_only=True)\n",
        "print(correlation_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWOqKuhH41Gl",
        "outputId": "91627ec4-db13-4bab-86d0-ef679a3de145"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       hadm_id  hospital_expire_flag  has_chartevents_data\n",
            "hadm_id               1.000000              0.062993             -0.132438\n",
            "hospital_expire_flag  0.062993              1.000000             -0.131844\n",
            "has_chartevents_data -0.132438             -0.131844              1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Valores de X:\")\n",
        "print(X)\n",
        "\n",
        "print(\"Valores de y:\")\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKnKeGGM5af5",
        "outputId": "97f2bfe5-7a04-4844-8bc4-39eb2cbfa920"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores de X:\n",
            "    hadm_id  hospital_expire_flag  has_chartevents_data\n",
            "0    142345                     0                     1\n",
            "2    165520                     1                     1\n",
            "11   189483                     1                     1\n",
            "19   100375                     0                     1\n",
            "69   182879                     0                     1\n",
            "78   176016                     0                     1\n",
            "82   180546                     0                     1\n",
            "84   125013                     0                     1\n",
            "89   149469                     0                     1\n",
            "90   153826                     0                     1\n",
            "Valores de y:\n",
            "0     0\n",
            "2     1\n",
            "11    1\n",
            "19    0\n",
            "69    1\n",
            "78    0\n",
            "82    1\n",
            "84    0\n",
            "89    1\n",
            "90    1\n",
            "Name: deathtime, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2xavqR315bQO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}